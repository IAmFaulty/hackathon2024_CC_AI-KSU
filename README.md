Hello!

This is the code for the our project
at the Kennesaw State Univeristy College of Computing and Software Engineering
Spring Hackathon for Social Good

This Android program uses the camera and Language/Face-tracking APIs
in order to recognize speech, show it as captions and track it to a persons face,
and having it act similar to a live captioning device for the hearing-impaired.

Team Name: Live Vision

Team Members: John Sheffield, Alhasan Mohsen, and Andrew Palmertree
